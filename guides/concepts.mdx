---
title: "Core Concepts"
description: "Understanding Nebula's architecture: memories, chunks, and containers"
---

# Core Concepts

Understanding Nebula's architecture helps you work more effectively with memories, conversations, and documents.

## Memories: Universal Information Containers

In Nebula, everything is stored as a **memory** - a container for related information:

- **Conversation Memory**: Contains all messages in a conversation
- **Document Memory**: Contains an entire document (potentially split into chunks)
- **Simple Memory**: Contains a single piece of information

### Memories vs Chunks

- **Memory**: The container with a unique `memory_id`
- **Chunks**: Individual pieces within a memory (messages in conversations, sections in documents)
- **Chunk ID**: Unique identifier for each chunk, used for granular operations

<CodeGroup>

```python Python
# Create a conversation memory
conv_id = client.store_memory({
    "collection_id": "support_chats",
    "content": "Hello! How can I help?",
    "role": "assistant"
})

# Add messages to the same conversation
client.store_memory({
    "memory_id": conv_id,
    "collection_id": "support_chats",
    "content": [
        {"content": "I need help", "role": "user"},
        {"content": "I'll help you", "role": "assistant"}
    ]
})
```

```javascript JavaScript
// Create a conversation memory
const convId = await nebula.storeMemory({
  collection_id: 'support_chats',
  content: 'Hello! How can I help?',
  role: 'assistant'
});

// Add messages to the same conversation
await nebula.storeMemory({
  memory_id: convId,
  collection_id: 'support_chats',
  content: [
    { content: 'I need help', role: 'user' },
    { content: 'I\'ll help you', role: 'assistant' }
  ]
});
```

```bash cURL
# Create conversation
curl -X POST "https://api.trynebula.ai/v1/memories" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -d '{
    "collection_id": "COLLECTION_ID",
    "engram_type": "conversation",
    "messages": [{"content": "Hello! How can I help?", "role": "assistant"}]
  }'

# Add messages (use memory_id from response)
curl -X POST "https://api.trynebula.ai/v1/memories" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -d '{
    "memory_id": "MEMORY_ID",
    "collection_id": "COLLECTION_ID",
    "engram_type": "conversation",
    "messages": [
      {"content": "I need help", "role": "user"},
      {"content": "I'\''ll help you", "role": "assistant"}
    ]
  }'
```

</CodeGroup>

## Types of Memories

### Document Memories
Contain entire documents, split into chunks internally for processing. You can upload text, pre-chunked text, or a file.

<CodeGroup>

```python Python
from nebula import Memory

# Store document text
doc_id = client.create_document_text(
    collection_id=collection.id,
    raw_text="Full document content...",
    metadata={"title": "Research Paper"}
)

# Upload a file
doc_id = client.store_memory(
    Memory.from_file("document.pdf", collection_id=collection.id, metadata={"title": "Research Paper"})
)
```

```javascript JavaScript
import Nebula, { Memory } from '@nebula-ai/sdk';

const nebula = new Nebula({ apiKey: 'your-api-key' });

// Store document text
const docId = await nebula.storeMemory({
  collection_id: 'research_papers',
  content: 'Full document content...',
  metadata: { title: 'Research Paper' }
});

// Upload a file (Node.js only)
const fileDocId = await nebula.storeMemory(
  await Memory.fromFile('document.pdf', 'research_papers', { title: 'Research Paper' })
);
```

```bash cURL
# Upload file (base64 encoded)
curl -X POST "https://api.trynebula.ai/v1/memories" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -d '{
    "collection_id": "COLLECTION_ID",
    "content_parts": [{
      "type": "document",
      "data": "BASE64_ENCODED_FILE_DATA",
      "media_type": "application/pdf",
      "filename": "document.pdf"
    }],
    "metadata": {"title": "Research Paper"}
  }'
```

</CodeGroup>

### Conversation Memories
Contain full conversations. Add messages by calling `store_memory()` with the same `memory_id`.
See [Conversations Guide](/guides/conversations) for examples.

### Simple Memories
Standalone pieces of information that don't need chunking.

```python
memory_id = client.store_memory({
    "collection_id": "preferences",
    "content": "User prefers dark mode",
    "metadata": {"user_id": "user_789"}
})
```

## Memory Lifecycle

1. **Creation**: `store_memory()` without `memory_id` creates new memory
2. **Expansion**: `store_memory()` with `memory_id` adds content to existing memory
3. **Retrieval**: `get_memory()` returns complete memory with all chunks
4. **Chunk Operations**: Use chunk IDs for granular updates/deletes
5. **Deletion**: `delete()` removes entire memory and all its chunks

## Best Practices

- **Build complete units**: Use `memory_id` to build entire conversations/documents in one container
- **Use descriptive metadata**: Identify memory types and add context
- **Choose appropriate collections**: Group related memories logically
- **Chunk operations when needed**: Use chunk IDs only for granular edits

## Next Steps

- [Memory Operations Guide](/guides/memory-operations) - Store, retrieve, and delete memories
- [Collections Guide](/guides/collections) - Organize memories into collections
