---
title: 'Memory Operations'
description: 'Store and search memories with practical examples'
---

# Memory Operations

Practical examples for storing and searching memories with the Nebula API.

## Core Operations

### Store Memories

**Single memory:**
<CodeGroup>

```python store_single.py
from nebula_client import NebulaClient

client = NebulaClient(api_key="your-api-key")

# Store a memory
memory_id = client.store_memory({
    "cluster_id": "research-cluster",
    "content": "Machine learning automates analytical model building",
    "metadata": {"topic": "AI", "difficulty": "intermediate"}
})
```

```javascript store_single.js
const { NebulaClient } = require('@nebula-ai/sdk');

const client = new NebulaClient({ apiKey: 'your-api-key' });

async function storeMemory() {
  const memoryId = await client.storeMemory({
    cluster_id: "research-cluster",
    content: "Machine learning automates analytical model building",
    metadata: { topic: "AI", difficulty: "intermediate" }
  });

  console.log(`Stored memory with ID: ${memoryId}`);
}

storeMemory();
```

</CodeGroup>

**Multiple memories:**
<CodeGroup>

```python store_multiple.py
from nebula_client import NebulaClient

client = NebulaClient(api_key="your-api-key")

# Store multiple memories at once
memories = [
    {
        "cluster_id": "research-cluster",
        "content": "Supervised learning uses labeled training data",
        "metadata": {"type": "definition", "topic": "ML"}
    },
    {
        "cluster_id": "research-cluster",
        "content": "Neural networks are inspired by biological systems",
        "metadata": {"type": "concept", "topic": "AI"}
    }
]
memory_ids = client.store_memories(memories)
```

```javascript store_multiple.js
const { NebulaClient } = require('@nebula-ai/sdk');

const client = new NebulaClient({ apiKey: 'your-api-key' });

async function storeMemories() {
  const memories = [
    {
      cluster_id: "research-cluster",
      content: "Supervised learning uses labeled training data",
      metadata: { type: "definition", topic: "ML" }
    },
    {
      cluster_id: "research-cluster",
      content: "Neural networks are inspired by biological systems",
      metadata: { type: "concept", topic: "AI" }
    }
  ];

  const memoryIds = await client.storeMemories(memories);
  console.log(`Stored memories with IDs: ${memoryIds}`);
}

storeMemories();
```

</CodeGroup>

**Conversation messages:**
<CodeGroup>

```python store_conversation.py
from nebula_client import NebulaClient

client = NebulaClient(api_key="your-api-key")

# Store conversation with roles
conversation_id = client.store_memory({
    "cluster_id": "support-cluster",
    "content": "Hello! How can I help you?",
    "role": "assistant",
    "metadata": {"session_id": "session_123"}
})

# User response
client.store_memory({
    "cluster_id": "support-cluster",
    "content": "I need help with my account",
    "role": "user",
    "parent_id": conversation_id
})
```

```javascript store_conversation.js
const { NebulaClient } = require('@nebula-ai/sdk');

const client = new NebulaClient({ apiKey: 'your-api-key' });

async function storeConversation() {
  // Store conversation with roles
  const conversationId = await client.storeMemory({
    cluster_id: "support-cluster",
    content: "Hello! How can I help you?",
    role: "assistant",
    metadata: { session_id: "session_123" }
  });

  // User response
  await client.storeMemory({
    cluster_id: "support-cluster",
    content: "I need help with my account",
    role: "user",
    parent_id: conversationId
  });

  console.log(`Stored conversation with ID: ${conversationId}`);
}

storeConversation();
```

</CodeGroup>

### Search Memories

Nebula provides intelligent hybrid search that automatically combines semantic (vector) and full-text search for optimal results.

**Basic search:**
<CodeGroup>

```python search_basic.py
from nebula_client import NebulaClient

client = NebulaClient(api_key="your-api-key")

# Simple search with default hybrid settings
results = client.search(
    query="machine learning algorithms",
    cluster_ids=["research-cluster"],
    search_settings={
        "limit": 10
    }
)

for result in results:
    print(f"Score: {result.score:.3f}")
    print(f"Content: {result.content[:100]}...")
    print(f"Metadata: {result.metadata}")
```

```javascript search_basic.js
const { NebulaClient } = require('@nebula-ai/sdk');

const client = new NebulaClient({ apiKey: 'your-api-key' });

async function searchMemories() {
  const results = await client.search({
    query: "machine learning algorithms",
    cluster_ids: ["research-cluster"],
    searchSettings: {
      limit: 10
    }
  });

  results.forEach(result => {
    console.log(`Score: ${result.score.toFixed(3)}`);
    console.log(`Content: ${result.content.substring(0, 100)}...`);
    console.log(`Metadata: ${JSON.stringify(result.metadata)}`);
  });
}

searchMemories();
```

</CodeGroup>

**Search with custom weights:**
<CodeGroup>

```python search_weights.py
from nebula_client import NebulaClient

client = NebulaClient(api_key="your-api-key")

# Control semantic vs full-text search balance
results = client.search(
    query="artificial intelligence",
    cluster_ids=["research-cluster"],
    search_settings={
        "limit": 10,
        "semantic_weight": 8.0,    # Emphasize conceptual matching
        "fulltext_weight": 2.0,    # Some keyword matching
        "include_scores": True,
        "include_metadatas": True
    }
)

print(f"Found {len(results)} results with hybrid search")
```

```javascript search_weights.js
const { NebulaClient } = require('@nebula-ai/sdk');

const client = new NebulaClient({ apiKey: 'your-api-key' });

async function searchWithWeights() {
  const results = await client.search({
    query: "artificial intelligence",
    cluster_ids: ["research-cluster"],
    searchSettings: {
      limit: 10,
      semantic_weight: 8.0,    // Emphasize conceptual matching
      fulltext_weight: 2.0,    // Some keyword matching
      include_scores: true,
      include_metadatas: true
    }
  });

  console.log(`Found ${results.length} results with hybrid search`);
}

searchWithWeights();
```

</CodeGroup>

**Search with type-specific limits:**
<CodeGroup>

```python search_types.py
from nebula_client import NebulaClient

client = NebulaClient(api_key="your-api-key")

# Control different result types separately
results = client.search(
    query="neural networks and machine learning",
    cluster_ids=["research-cluster"],
    search_settings={
        "limit": 25,
        "type_limits": {
            "entity_limit": 10,        # Key concepts and entities
            "relationship_limit": 8,   # Connections between concepts
            "community_limit": 3,      # Topic clusters
            "chunk_limit": 15          # Text passages
        }
    }
)

# Results will contain mixed types with specific limits
for result in results:
    print(f"Type: {result.result_type}, Content: {result.content[:80]}...")
```

```javascript search_types.js
const { NebulaClient } = require('@nebula-ai/sdk');

const client = new NebulaClient({ apiKey: 'your-api-key' });

async function searchWithTypeLimits() {
  const results = await client.search({
    query: "neural networks and machine learning",
    cluster_ids: ["research-cluster"],
    searchSettings: {
      limit: 25,
      type_limits: {
        entity_limit: 10,        // Key concepts and entities
        relationship_limit: 8,   // Connections between concepts
        community_limit: 3,      // Topic clusters
        chunk_limit: 15          // Text passages
      }
    }
  });

  // Results contain mixed types with specific limits
  results.forEach(result => {
    console.log(`Type: ${result.result_type}, Content: ${result.content.substring(0, 80)}...`);
  });
}

searchWithTypeLimits();
```

</CodeGroup>

**Advanced filtering:**
<CodeGroup>

```python search_advanced.py
from nebula_client import NebulaClient

client = NebulaClient(api_key="your-api-key")

# Advanced search with metadata filtering and graph traversal
results = client.search(
    query="research methodology",
    cluster_ids=["research-cluster"],
    search_settings={
        "limit": 15,
        "semantic_weight": 6.0,
        "fulltext_weight": 3.0,
        "filters": {
            "metadata.topic": {"$eq": "methodology"},
            "source_role": "researcher",      # Graph filtering by speaker role
            "owner_scope": ["team_lead"]      # Limit to specific contributors
        },
        "type_limits": {
            "entity_limit": 8,
            "chunk_limit": 12
        }
    }
)

print(f"Found {len(results)} specialized research results")
```

```javascript search_advanced.js
const { NebulaClient } = require('@nebula-ai/sdk');

const client = new NebulaClient({ apiKey: 'your-api-key' });

async function advancedSearch() {
  const results = await client.search({
    query: "research methodology",
    cluster_ids: ["research-cluster"],
    searchSettings: {
      limit: 15,
      semantic_weight: 6.0,
      fulltext_weight: 3.0,
      filters: {
        "metadata.topic": { $eq: "methodology" },
        source_role: "researcher",      // Graph filtering by speaker role
        owner_scope: ["team_lead"]      // Limit to specific contributors
      },
      type_limits: {
        entity_limit: 8,
        chunk_limit: 12
      }
    }
  });

  console.log(`Found ${results.length} specialized research results`);
}

advancedSearch();
```

</CodeGroup>

### Delete Memories

**Delete single memory:**
<CodeGroup>

```python delete_single.py
from nebula_client import NebulaClient

client = NebulaClient(api_key="your-api-key")

# Delete a single memory
success = client.delete("memory_id_here")
print(f"Deleted: {success}")  # True
```

```javascript delete_single.js
const { NebulaClient } = require('@nebula-ai/sdk');

const client = new NebulaClient({ apiKey: 'your-api-key' });

async function deleteMemory() {
  const success = await client.delete('memory_id_here');
  console.log(`Deleted: ${success}`);  // true
}

deleteMemory();
```

</CodeGroup>

**Delete multiple memories (batch):**
<CodeGroup>

```python delete_batch.py
from nebula_client import NebulaClient

client = NebulaClient(api_key="your-api-key")

# Delete multiple memories in a single efficient operation
memory_ids = ["mem_id_1", "mem_id_2", "mem_id_3", "mem_id_4"]
result = client.delete(memory_ids)

# Access detailed results
print(f"Message: {result['message']}")
print(f"Successfully deleted: {result['results']['successful']}")
print(f"Failed deletions: {result['results']['failed']}")
print(f"Total: {result['results']['summary']['total']}")
print(f"Succeeded: {result['results']['summary']['succeeded']}")
print(f"Failed: {result['results']['summary']['failed']}")

# Example response:
# {
#   "message": "Deleted 3 of 4 documents",
#   "results": {
#     "successful": ["mem_id_1", "mem_id_2", "mem_id_3"],
#     "failed": [{"id": "mem_id_4", "error": "Not found or no permission"}],
#     "summary": {"total": 4, "succeeded": 3, "failed": 1}
#   }
# }
```

```javascript delete_batch.js
const { NebulaClient } = require('@nebula-ai/sdk');

const client = new NebulaClient({ apiKey: 'your-api-key' });

async function deleteBatch() {
  // Delete multiple memories in a single efficient operation
  const memoryIds = ['mem_id_1', 'mem_id_2', 'mem_id_3', 'mem_id_4'];
  const result = await client.delete(memoryIds);

  // Access detailed results
  console.log(`Message: ${result.message}`);
  console.log(`Successfully deleted: ${result.results.successful}`);
  console.log(`Failed deletions:`, result.results.failed);
  console.log(`Total: ${result.results.summary.total}`);
  console.log(`Succeeded: ${result.results.summary.succeeded}`);
  console.log(`Failed: ${result.results.summary.failed}`);

  // Example response:
  // {
  //   message: "Deleted 3 of 4 documents",
  //   results: {
  //     successful: ["mem_id_1", "mem_id_2", "mem_id_3"],
  //     failed: [{id: "mem_id_4", error: "Not found or no permission"}],
  //     summary: {total: 4, succeeded: 3, failed: 1}
  //   }
  // }
}

deleteBatch();
```

</CodeGroup>

<Tip>
Use batch deletion when removing multiple memories to significantly improve performance. The batch operation uses efficient database-level filtering instead of iterating through individual deletions.
</Tip>

### Retrieve & List Memories

**Get specific memory:**
<CodeGroup>

```python get_memory.py
from nebula_client import NebulaClient

client = NebulaClient(api_key="your-api-key")

# Retrieve a memory by ID
memory = client.get_memory(memory_id)
print(f"Content: {memory.content}")
print(f"Metadata: {memory.metadata}")
print(f"Created: {memory.created_at}")
```

```javascript get_memory.js
const { NebulaClient } = require('@nebula-ai/sdk');

const client = new NebulaClient({ apiKey: 'your-api-key' });

async function getMemory(memoryId) {
  const memory = await client.getMemory(memoryId);
  console.log(`Content: ${memory.content}`);
  console.log(`Metadata: ${JSON.stringify(memory.metadata)}`);
  console.log(`Created: ${memory.created_at}`);
}

getMemory("memory_id_here");
```

</CodeGroup>

**List memories in cluster:**
<CodeGroup>

```python list_memories.py
from nebula_client import NebulaClient

client = NebulaClient(api_key="your-api-key")

# List memories in a cluster
memories = client.list_memories(
    cluster_ids=["research-cluster"],
    limit=20,
    offset=0
)

for memory in memories:
    print(f"ID: {memory.id}")
    print(f"Content: {memory.content[:60]}...")
    print(f"Created: {memory.created_at}")
```

```javascript list_memories.js
const { NebulaClient } = require('@nebula-ai/sdk');

const client = new NebulaClient({ apiKey: 'your-api-key' });

async function listMemories() {
  const memories = await client.listMemories({
    cluster_ids: ["research-cluster"],
    limit: 20,
    offset: 0
  });

  memories.forEach(memory => {
    console.log(`ID: ${memory.id}`);
    console.log(`Content: ${memory.content.substring(0, 60)}...`);
    console.log(`Created: ${memory.created_at}`);
  });
}

listMemories();
```

</CodeGroup>

## Complete Workflow

<CodeGroup>

```python workflow.py
from nebula_client import NebulaClient

client = NebulaClient(api_key="your-api-key")

# 1. Create cluster and store memories
cluster = client.create_cluster("demo-cluster", "Example cluster")
memories = [
    {
        "cluster_id": cluster.id,
        "content": "Python is a high-level programming language",
        "metadata": {"language": "python", "type": "fact"}
    },
    {
        "cluster_id": cluster.id,
        "content": "JavaScript is used for web development",
        "metadata": {"language": "javascript", "type": "fact"}
    }
]
memory_ids = client.store_memories(memories)

# 2. Search memories
results = client.search(
    query="programming languages",
    cluster_ids=[cluster.id],
    limit=5
)

# 3. Retrieve specific memory
memory = client.get_memory(memory_ids[0])
print(f"Retrieved: {memory.content}")

# 4. Delete memories (single and batch)
# Delete single memory
deleted = client.delete(memory_ids[0])
print(f"Single deletion: {deleted}")

# Delete remaining memories in batch
batch_result = client.delete(memory_ids[1:])
print(f"Batch deletion: {batch_result['message']}")
```

```javascript workflow.js
const { NebulaClient } = require('@nebula-ai/sdk');

const client = new NebulaClient({
  apiKey: 'your-api-key'
});

async function runWorkflow() {
  // 1. Create cluster and store memories
  const cluster = await client.createCluster({
    name: "demo-cluster",
    description: "Example cluster"
  });

  const memories = [
    {
      cluster_id: cluster.id,
      content: "Python is a high-level programming language",
      metadata: { language: "python", type: "fact" }
    },
    {
      cluster_id: cluster.id,
      content: "JavaScript is used for web development",
      metadata: { language: "javascript", type: "fact" }
    }
  ];

  const memoryIds = await client.storeMemories(memories);

  // 2. Search memories
  const results = await client.search({
    query: "programming languages",
    cluster_ids: [cluster.id],
    limit: 5
  });

  // 3. Retrieve specific memory
  const memory = await client.getMemory(memoryIds[0]);
  console.log(`Retrieved: ${memory.content}`);

  // 4. Delete memories (single and batch)
  // Delete single memory
  const deleted = await client.delete(memoryIds[0]);
  console.log(`Single deletion: ${deleted}`);

  // Delete remaining memories in batch
  const batchResult = await client.delete(memoryIds.slice(1));
  console.log(`Batch deletion: ${batchResult.message}`);
}

runWorkflow();
```

</CodeGroup>

## Advanced Search Settings

For power users who need fine-grained control over search behavior, Nebula provides advanced search settings through the optional `search_settings` parameter.

### Hybrid Search Weights

Control the balance between semantic (conceptual) and full-text (keyword) search:

<CodeGroup>

```python weights.py
# Pure semantic search (conceptual matching only)
results = client.search(
    query="artificial intelligence concepts",
    cluster_ids=["research-cluster"],
    search_settings={
        "semantic_weight": 10.0,
        "fulltext_weight": 0.0
    }
)

# Pure full-text search (keyword matching only)
results = client.search(
    query="machine learning API documentation",
    cluster_ids=["docs-cluster"],
    search_settings={
        "semantic_weight": 0.0,
        "fulltext_weight": 10.0
    }
)

# Balanced hybrid search (default behavior)
results = client.search(
    query="neural network implementation",
    cluster_ids=["research-cluster"],
    search_settings={
        "semantic_weight": 5.0,    # Default
        "fulltext_weight": 1.0     # Default
    }
)
```

```javascript weights.js
// Pure semantic search (conceptual matching only)
const results = await client.search({
  query: "artificial intelligence concepts",
  cluster_ids: ["research-cluster"],
  searchSettings: {
    semantic_weight: 10.0,
    fulltext_weight: 0.0
  }
});

// Pure full-text search (keyword matching only)
const results = await client.search({
  query: "machine learning API documentation",
  cluster_ids: ["docs-cluster"],
  searchSettings: {
    semantic_weight: 0.0,
    fulltext_weight: 10.0
  }
});

// Balanced hybrid search (default behavior)
const results = await client.search({
  query: "neural network implementation",
  cluster_ids: ["research-cluster"],
  searchSettings: {
    semantic_weight: 5.0,    // Default
    fulltext_weight: 1.0     // Default
  }
});
```

</CodeGroup>

### Type-Specific Limits

Control how many results to return for each type of search result:

<CodeGroup>

```python type_limits.py
results = client.search(
    query="machine learning research methodology",
    cluster_ids=["research-cluster"],
    search_settings={
        "limit": 25,               # Total result limit
        "type_limits": {
            "entity_limit": 8,      # Key concepts and entities
            "relationship_limit": 5, # Connections between concepts
            "community_limit": 2,    # Topic clusters
            "chunk_limit": 15        # Text passages
        }
    }
)
```

```javascript type_limits.js
const results = await client.search({
  query: "machine learning research methodology",
  cluster_ids: ["research-cluster"],
  searchSettings: {
    limit: 25,               // Total result limit
    type_limits: {
      entity_limit: 8,       // Key concepts and entities
      relationship_limit: 5, // Connections between concepts
      community_limit: 2,    // Topic clusters
      chunk_limit: 15        // Text passages
    }
  }
});
```

</CodeGroup>

### Canonical Filter Keys

Use special filter keys that Nebula interprets internally for graph-based operations:

<CodeGroup>

```python canonical_filters.py
# Filter by conversation roles and ownership
results = client.search(
    query="user requirements and feedback",
    cluster_ids=["support-cluster"],
    search_settings={
        "filters": {
            "source_role": "user",           # Graph traversal by speaker role
            "owner_scope": ["team_lead"],    # Limit to specific contributors
            "metadata.priority": "high"      # Regular metadata filtering
        }
    }
)
```

```javascript canonical_filters.js
// Filter by conversation roles and ownership
const results = await client.search({
  query: "user requirements and feedback",
  cluster_ids: ["support-cluster"],
  searchSettings: {
    filters: {
      source_role: "user",           // Graph traversal by speaker role
      owner_scope: ["team_lead"],    // Limit to specific contributors
      "metadata.priority": "high"    // Regular metadata filtering
    }
  }
});
```

</CodeGroup>

**Special filter keys:**
- `source_role`: Filter by conversation role (user, assistant, system)
- `owner_scope`: Filter by content contributor/owner
- `metadata.*`: Standard metadata filtering

## Chunk-Level Authority (Advanced Feature)

Nebula supports **chunk-level authority** to control the influence of specific messages or content in retrieval and ranking. This is particularly useful for conversation data where different speakers may have varying levels of expertise or credibility.

### How It Works

When you add messages to a conversation, you can specify an `authority` value (0.0 to 1.0) that affects how that content is weighted during search and retrieval:

- **0.0**: No authority (content has minimal influence)
- **0.5**: Neutral authority (default)
- **1.0**: Maximum authority (content has strong influence)

### Usage Examples

**High-authority expert content:**
```python
# Expert opinion with high authority
client.conversations.add_message(
    conversation_id="conv-123",
    messages=[{
        "content": "Based on my 20 years of experience in machine learning, this approach is optimal.",
        "role": "user",
        "authority": 0.9  # High authority for expert content
    }],
    collection_id="research-cluster"
)
```

**Low-authority system messages:**
```python
# System notification with low authority
client.conversations.add_message(
    conversation_id="conv-123", 
    messages=[{
        "content": "System maintenance scheduled for tonight.",
        "role": "system",
        "authority": 0.2  # Low authority for system messages
    }],
    collection_id="research-cluster"
)
```

**Default authority (when not specified):**
```python
# No authority specified - uses default 0.5
client.conversations.add_message(
    conversation_id="conv-123",
    messages=[{
        "content": "Regular user message",
        "role": "user"
        # authority defaults to 0.5
    }],
    collection_id="research-cluster"
)
```

### Authority in Retrieval

During search and retrieval, Nebula uses the authority values to:

1. **Weight speaker embeddings** - Higher authority speakers have more influence
2. **Boost relevant content** - High-authority content gets ranking boosts

The authority system works seamlessly with Nebula's existing retrieval strategies, including BFS traversal and set transformer components.

<Warning>
Authority values are stored in chunk metadata and persist across searches. Use this feature thoughtfully to maintain search quality and avoid bias.
</Warning>

## Best Practices

- **Use descriptive metadata** for better organization and filtering
- **Batch operations** with `store_memories()` for multiple items
- **Set appropriate limits** in search to manage performance
- **Use natural language queries** for best search results
- **Validate required fields** before storing memories
- **Start with basic search** and only use advanced settings when needed

<Tip>Attach focused, query-relevant metadata (e.g., topic, type, priority) to improve search precision and filtering.</Tip>

## Next Steps

- [Clusters Guide](/guides/clusters) - Organize memories effectively
- [Conversations Guide](/guides/conversations) - Build conversational AI
- [API Reference](/api-reference/overview) - Complete endpoint documentation
